{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "import chardet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"worldcitiespop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"Population\"], ascending=False)\n",
    "df = df.drop_duplicates(subset=[\"AccentCity\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = set(df[\"AccentCity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cities(file_text):\n",
    "    word_list = re.sub(\"[^\\w]\", \" \",  file_text).split()\n",
    "    return list(all_cities.intersection(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details(file_text):\n",
    "    re_patterns = [\n",
    "        \"[ ]{0,4}Title: (.+)\\n\\n[ ]{0,4}Author: ([^\\n]+)\\n\",\n",
    "        \"  We need your donations.\\n\\n\\n([^\\n]+)\\n\\nby ([^\\n]+)\\n\\n\",\n",
    "        \"\\n\\nTitle: (.+)\\nAuthor: (.+)\\nRelease Date: \",\n",
    "        \"\\n\\n\\n\\n\\n\\n[\\d]{4}\\n\\n()\\n\\nby ()\\n\\n\\nDramatis Personae\",\n",
    "    ]\n",
    "\n",
    "    title = None\n",
    "    author = None\n",
    "\n",
    "    for pattern in re_patterns:\n",
    "        try:\n",
    "            result = re.search(pattern, file_text, re.DOTALL)\n",
    "            title = result.group(1)\n",
    "            author = result.group(2)\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return title, author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London', 'Paris']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_cities(\"Paris is better than London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vanilla', 'England', 'France', 'West', 'Fournier', 'They', 'That', 'Bon', 'March', 'Frederick', 'Domain', 'Royalty', 'Past', 'Move', 'Endor', 'Has', 'Walt', 'Bennett', 'Richard', 'Sun', 'Research', 'Ocean', 'Story', 'Aladdin', 'Purdy', 'More', 'On', 'Then', 'Mission', 'Rather', 'As', 'Owen', 'Hades', 'Were', 'Prince', 'Napoleon', 'Kodak', 'Boston', 'Look', 'Most', 'Helen', 'Difficult', 'Tristan', 'Some', 'Aisha', 'Offer', 'Challis', 'Esperance', 'Pity', 'Ford', 'Now', 'Clark', 'Forel', 'Zerah', 'Thompson', 'Deep', 'Richet', 'United', 'German', 'Plato', 'Fontan', 'Stetson', 'Ellen', 'Yolande', 'Sin', 'Passage', 'Sir', 'Vague', 'General', 'Quite', 'Saxon', 'Soul', 'Jan', 'No', 'Love', 'Maupas', 'Are', 'Plain', 'Little', 'One', 'Homer', 'Garden', 'Burns', 'About', 'Turin', 'Section', 'Thou', 'Divine', 'Ellis', 'Norway', 'Over', 'Villa', 'Of', 'Garibaldi', 'Terror', 'During', 'To', 'Bible', 'Edmund', 'Am', 'Livermore', 'Dec', 'Naples', 'Duncan', 'Those', 'Asra', 'Nor', 'Edward', 'Leduc', 'Human', 'Tree', 'By', 'We', 'Pagan', 'Many', 'Spider', 'York', 'Whitehall', 'Western', 'Louise', 'You', 'Among', 'Yoga', 'The', 'Descartes', 'Under', 'For', 'Newby', 'Want', 'Man', 'Poverty', 'Thing', 'Universal', 'New', 'Florence', 'Hercules', 'A', 'British', 'Robert', 'Sally', 'My', 'Archive', 'Self', 'Lay', 'This', 'Salt', 'Scott', 'Griffin', 'Keller', 'Carpenter', 'Minister', 'Christ', 'Tetlow', 'Wilson', 'Katie', 'How', 'Oh', 'Say', 'Bruno', 'Ich', 'Tell', 'Heart', 'Baraduc', 'Augustus', 'Town', 'French', 'Spirit', 'Few', 'True', 'Fischer', 'Birth', 'Yea', 'Farr', 'Me', 'Sunday', 'Haig', 'Freedom', 'City', 'So', 'Eden', 'Martha', 'English', 'Will', 'Key', 'Dante', 'Wesley', 'Five', 'Anglo', 'Sergeant', 'Any', 'Wallace', 'Indian', 'Quincey', 'Bishop', 'Lodge', 'Boa', 'Hirschfeld', 'Never', 'Their', 'Darwin', 'Maxwell', 'Service', 'John', 'Shelley', 'Jiva', 'Havelock', 'Yet', 'Here', 'Angel', 'Paris', 'And', 'Attention', 'Beauty', 'Guardian', 'Navy', 'Henri', 'Der', 'Birmingham', 'Again', 'Albe', 'End', 'Such', 'Hudson', 'Swiss', 'Algeria', 'William', 'Powers', 'Camille', 'Public', 'Orpheus', 'Morgan', 'Myers', 'Nevis', 'Bell', 'Lead', 'Happy', 'Arthur', 'Berlin', 'Kate', 'Katha', 'Auguste', 'Daphne', 'Ebing', 'Thus', 'Giant', 'Wright', 'Does', 'Romance', 'Michael', 'Art', 'Civil', 'Siegfried', 'Contact', 'Jacques', 'Charity', 'Titanic', 'James', 'O', 'Thomson', 'Lima', 'Purgatory', 'Race', 'Morton', 'Non', 'Annie', 'U', 'Like', 'An', 'Heine', 'Oliver', 'Colburn', 'Constable', 'Briggs', 'Sonnenschein', 'Cox', 'Bramwell', 'Jesus', 'Babe', 'Body', 'Walter', 'Return', 'She', 'Fidelity', 'Le', 'Romans', 'Plant', 'Still', 'Force', 'Stuttgart', 'Friday', 'Lover', 'Note', 'Since', 'Had', 'Lord', 'George', 'Melan', 'When', 'Complex', 'Lanark', 'Chicago', 'Drama', 'Or', 'Ville', 'Macdonald', 'Gustave', 'America', 'Die', 'Church', 'Earth', 'May', 'De', 'Carrington', 'Life', 'Mme', 'London', 'Nowhere', 'Coleridge', 'Cause', 'Her', 'Fox', 'Kraft', 'Why', 'There', 'Re', 'Gutenberg', 'War', 'June', 'Jericho', 'Pandora', 'X', 'August', 'Equality', 'Fairbanks', 'Hunger', 'Vulcan', 'Ben', 'Full', 'Yolanda', 'Revenue', 'Milne', 'Loeb', 'Cook', 'Charles', 'Rolleston', 'Colonna', 'Cinderella', 'Keighley', 'Latin', 'Egypt', 'Gregory', 'Both', 'Allen', 'Hart', 'Ovid', 'Young', 'Plutarch', 'North', 'Only', 'Our', 'See', 'Taking', 'Geddes', 'Is', 'Norfolk', 'Gurney', 'Paradise', 'Accident', 'His', 'Carmen', 'Ego', 'Leipzig', 'Beni', 'I', 'Date', 'Semon', 'Web', 'Use', 'Let', 'Beauchamp', 'Putnam', 'Das', 'Not', 'Atom', 'Muir', 'Thoreau', 'But', 'Radium', 'Otto', 'Field', 'Dale', 'All', 'Do', 'Christian', 'Congress', 'Rose', 'Tichborne', 'Piper', 'Duckworth', 'Lake', 'February', 'Whitman', 'At', 'He', 'In', 'Star', 'Nay', 'From', 'Estella', 'Boundary', 'Men', 'Time', 'Willington', 'Light', 'Und', 'Oscar', 'Whitehead', 'Fall', 'King', 'Observatory', 'Svet', 'Smith']\n",
      "44883.txt\n",
      "TITLE: The Drama of Love and Death\n",
      "       A Study of Human Evolution and Transfiguration\n",
      "AUTHOR: Edward Carpenter\n",
      "\n",
      "Succes: 1\n",
      "Fail: 0\n",
      "regex_errors: 0\n",
      "encoding_error: 0\n",
      "Total: 1\n"
     ]
    }
   ],
   "source": [
    "txt_files = [f for f in listdir() if f.endswith(\".txt\")]\n",
    "#txt_files = [txt_files[0]]\n",
    "success = 0\n",
    "fail = 0\n",
    "\n",
    "encoding_failed = []\n",
    "regex_failed = []\n",
    "\n",
    "for file_name in txt_files:\n",
    "    \n",
    "    with open(file_name, 'r') as file:\n",
    "        \n",
    "        try:\n",
    "            file_text = file.read()\n",
    "            \n",
    "            print(extract_cities(file_text))\n",
    "            \n",
    "            title, author = extract_details(file_text)\n",
    "            \n",
    "            if author == None or title == None:\n",
    "                print(file_name + \"******REGEX*************************************************\")\n",
    "                fail += 1\n",
    "                regex_failed.append(file_name)\n",
    "            else:\n",
    "                print(file_name)\n",
    "                print(\"TITLE: \" + title)\n",
    "                print(\"AUTHOR: \" + author + \"\\n\")\n",
    "                success += 1\n",
    "                \n",
    "        except:\n",
    "            print(file_name + \"********ENCODING***********************************************\")\n",
    "            fail += 1\n",
    "            encoding_failed.append(file_name)\n",
    "\n",
    "print(\"Succes: \" + str(success))\n",
    "print(\"Fail: \" + str(fail))\n",
    "print(\"regex_errors: \" + str(len(regex_failed)))\n",
    "print(\"encoding_error: \" + str(len(encoding_failed)))\n",
    "print(\"Total: \" + str(len(txt_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoding_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
